{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAPM model\n",
    "#Weight => as in from asset allocation \n",
    "# rPortfolio = summationi(weighti (betai*rMarket)+ alphai)\n",
    "#Technical indicators\n",
    "# n is window size (20)\n",
    "# 1. Momentum -> (price[t]/price[t-n]) -1\n",
    "# 2. Simple moving average(SMA) -> (price[t]/price[t-n:t].mean())-1\n",
    "# 3. Bollinger band -> (price[t] - SMA[t]/2*std[t])-1\n",
    "# +2 std => value >1.0\n",
    "# -2 std => value <1.0\n",
    "\n",
    "# Range of these technical indicators\n",
    "# SMA => -0.5 to +0.5\n",
    "# MOMENTUM => -0.5 to +0.5\n",
    "# BB -> -1.0 to +1.0\n",
    "# PE ratio -> 1 to 300 (Fundamental)\n",
    "\n",
    "# These factors need to be normalized before using the combination of these indicators\n",
    "# normed = (values - mean)/values.std()\n",
    "\n",
    "# Stock split causes price changes. Data anomoly. So we use Adjusted price.\n",
    "\n",
    "# one should use survival bias free data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML dataset\n",
    "# X- axis => price momentum, Bolinger value, current price , PE ratio\n",
    "# Y- axis => future price, future return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from random import sample \n",
    "import time\n",
    "\n",
    "# import envs import TradingEnv\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run(symbols,date):\n",
    "    \n",
    "    dates= pd.date_range(date[0],date[1])\n",
    "    \n",
    "    #create empty dataframe\n",
    "    df1 = pd.DataFrame(index=dates)\n",
    "\n",
    "    for symbol in symbols:\n",
    "        df_temp=pd.read_csv(\"data/{}.csv\".format(symbol),index_col=\"Date\",\n",
    "                        parse_dates=True,usecols=['Date','Adj Close'],\n",
    "                        na_values=['nan'])\n",
    "        #rename to prevent clash\n",
    "        df_temp=df_temp.rename(columns={'Adj Close':symbol})\n",
    "        df1=df1.join(df_temp,how=\"inner\")\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_returns(df):\n",
    "    daily_returns = df.copy()\n",
    "    daily_returns[1:] = (df[1:]/df[:-1].values) -1\n",
    "    daily_returns.iloc[0,:]=0\n",
    "    return daily_returns\n",
    "def feature(df,window):\n",
    "    momentum = df.copy()\n",
    "    for i in range(len(df)):\n",
    "        if i < window:\n",
    "            momentum.iloc[i]=0\n",
    "        else:\n",
    "            momentum.iloc[i] = (df.iloc[i]/df.iloc[i-window]) -1\n",
    "    momentum = (momentum - momentum.mean())/momentum.std()\n",
    "    \n",
    "    SMA = df.copy()\n",
    "    for i in range(len(df)):\n",
    "        if i < window:\n",
    "            SMA.iloc[i]=0\n",
    "        else:\n",
    "            SMA.iloc[i] = (df.iloc[i]/df.iloc[i-window:i].mean()) -1\n",
    "    \n",
    "    SMA_std = df.copy()\n",
    "    for i in range(len(df)):\n",
    "        if i < window:\n",
    "            SMA_std.iloc[i]=0\n",
    "        else:\n",
    "            SMA_std.iloc[i] = (df.iloc[i]/df.iloc[i-window:i].std()) -1\n",
    "    \n",
    "    BBU = SMA + SMA_std*2\n",
    "    BBL = SMA - SMA_std*2\n",
    "    BBU = (BBU - BBU.mean())/BBU.std()\n",
    "    BBL = (BBL - BBL.mean())/BBL.std()\n",
    "    \n",
    "    #Calculating adjusted_close / SMA\n",
    "    ad_SMA = df.copy()\n",
    "    for i in range(len(df)):\n",
    "        if i < window:\n",
    "            ad_SMA.iloc[i]=0\n",
    "        else:\n",
    "            ad_SMA.iloc[i] = (df.iloc[i]/SMA.iloc[i]) -1\n",
    "    return ad_SMA, momentum, BBU, BBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols=['ITC.NS']\n",
    "date=[\"2017-4-26\",\"2018-10-9\"]\n",
    "windows = 20\n",
    "df = test_run(symbols,date)\n",
    "df = df.fillna(method='ffill')\n",
    "df = df.fillna(method='bfill')\n",
    "# print(df)\n",
    "\n",
    "df['ad_SMA'], df['momentum'], df['BBU'], df['BBL'] = feature(df,windows)\n",
    "df = df.iloc[windows:]\n",
    "print(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run envs.ipynb\n",
    "length = len(df)\n",
    "train_dataset = df[:math.floor((length*0.8))]\n",
    "test_dataset = df[math.ceil((length*0.8)):]\n",
    "# env = TradingEnv(train_dataset)\n",
    "train_dataset.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(state_shape,out_shape):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(100, activation='relu', input_shape=state_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(out_shape, activation=None)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.005),\n",
    "        loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(env_name,count_episode,count_per_episode,discount_rate,exploration_decay):\n",
    "    #Generate Environment\n",
    "    # action 0 Hold 1 Buy/sell depending upon holding\n",
    "    state_shape = (5,)\n",
    "    action_space = [0,1]\n",
    "    action_shape = len(action_space)\n",
    "    \n",
    "    #Create initial and target Model\n",
    "    model= create_model(state_shape,action_shape)\n",
    "    target_model = create_model(state_shape,action_shape)\n",
    "    \n",
    "    #Initialize lists\n",
    "    print_reward = []\n",
    "    memoization_list = []\n",
    "    \n",
    "    #setting up exploration rates\n",
    "    exploration_rate = 1\n",
    "    min_exploration_rate = 0.01\n",
    "    \n",
    "    #Running for every episode\n",
    "    for episode in range(count_episode):\n",
    "        env = TradingEnv(train_dataset)\n",
    "        state = [df.iloc[0]['ad_SMA'],df.iloc[0]['momentum'],df.iloc[0]['BBU'],0,0]\n",
    "        state = np.array(state).reshape(1,state_shape[0])\n",
    "        holding = 0\n",
    "        \n",
    "        #Dacaying the exploration rate after every episode\n",
    "        exploration_rate =  exploration_rate * exploration_decay\n",
    "        exploration_rate = max(exploration_rate,min_exploration_rate)\n",
    "        \n",
    "        #Total Reward will be the learning curve\n",
    "        totalReward = 0\n",
    "        \n",
    "        for step in range(count_per_episode):\n",
    "\n",
    "            #explore or exploit\n",
    "            tmp = random.uniform(0,1)\n",
    "            if tmp<exploration_rate:\n",
    "                action = random.sample(action_space, 1)\n",
    "#                 print(\"random\",action)\n",
    "            else:\n",
    "                action = np.argmax(model.predict(state)[0])\n",
    "#                 print(\"predicted\",action)\n",
    "            \n",
    "            #Apply action on environment\n",
    "            new_state,obs, reward,done,holding = env._step(action,holding)\n",
    "#             print(holding)\n",
    "            print(obs)\n",
    "\n",
    "            new_state = np.array(new_state).reshape(1,state_shape[0])\n",
    "            \n",
    "            #store state action information\n",
    "#             print(reward)\n",
    "            totalReward +=reward\n",
    "            memoization_list.append([state,action,reward,new_state,done])\n",
    "            \n",
    "            #Fit into model\n",
    "            if(len(memoization_list)>20):\n",
    "                samples = sample(memoization_list,20)\n",
    "    #             eachSample = memoization_list[step]\n",
    "                for eachSample in samples:\n",
    "                    old_state, action, reward, new_state, done = eachSample\n",
    "                    target = target_model.predict(old_state)\n",
    "                    if done:\n",
    "                        target[0][action] = reward\n",
    "                    else:\n",
    "                        expected_reward = max(target_model.predict(new_state)[0])\n",
    "                        target[0][action] = reward + expected_reward * discount_rate\n",
    "                    model.fit(old_state, target, epochs=1, verbose=0)\n",
    "            \n",
    "            #Updating weights into target model\n",
    "            state = new_state\n",
    "            weights = model.get_weights()\n",
    "            target_weights = target_model.get_weights()\n",
    "            for i in range(len(target_weights)):\n",
    "                target_weights[i] = weights[i] * 0.1 + target_weights[i] * 0.9\n",
    "            target_model.set_weights(target_weights)\n",
    "            if done:\n",
    "                break\n",
    "        print_reward.append(totalReward)\n",
    "        print(totalReward)\n",
    "    return print_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN(\"MountainCar-v0\",100,len(train_dataset)-1,0.99,0.95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
